{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd8c1d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA A: configuracion global\n",
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np, json, torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = 42\n",
    "MODEL_NAME = \"dccuchile/bert-base-spanish-wwm-cased\"\n",
    "OUT_BASE = Path(\"../models/beto_kfold\")\n",
    "FOLDS_CSV = Path(\"../data/processed/clean_v2/folds/corpus_clean_v2_folds.csv\")\n",
    "OUT_BASE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Hiperparámetros que vamos a ajustar\n",
    "N_EPOCHS = 4                # subir a 3-5 para ver mejora\n",
    "LR = 2e-5\n",
    "TRAIN_BS = 8                # si falta VRAM bajar a 4\n",
    "EVAL_BS = 32\n",
    "WEIGHT_DECAY = 0.01\n",
    "LOGGING_STEPS = 50\n",
    "SAVE_TOTAL_LIMIT = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b83dc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "num_labels: 4 label2id: {'0': 0, '1': 1, '2': 2, '3': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\_ JCAM 2010-2028\\_3_MASTERAI_UNI\\Ciclo4\\Tesis 2 Proyecto\\ProyectoClasificador\\ClasificadorsemanticoBETO\\beto_gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== TRAIN FOLD 0 ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f3184bce744ccf9516bbe5688a665f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/793 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c796b6c56c45a2a3e4e6e8c19c196e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/198 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9ea857b0934bf4818247ff638e3856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/793 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "410fae7aa88f47879e03ffd51499f39c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/198 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\_ JCAM 2010-2028\\_3_MASTERAI_UNI\\Ciclo4\\Tesis 2 Proyecto\\ProyectoClasificador\\ClasificadorsemanticoBETO\\beto_gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe37a862ffd4afa9dfee1c100228318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4661, 'learning_rate': 1.6733333333333335e-05, 'epoch': 0.5}\n",
      "{'loss': 0.0202, 'learning_rate': 1.3466666666666668e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b618068db92a4786b9fafd7a4ba4cbb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0037644030526280403, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_precision_macro': 1.0, 'eval_recall_macro': 1.0, 'eval_runtime': 0.3648, 'eval_samples_per_second': 542.749, 'eval_steps_per_second': 35.635, 'epoch': 1.0}\n",
      "{'loss': 0.0049, 'learning_rate': 1.0133333333333335e-05, 'epoch': 1.5}\n",
      "{'loss': 0.0036, 'learning_rate': 6.800000000000001e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "524b812341ba475ca660663d1be5c3e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0018961597234010696, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_precision_macro': 1.0, 'eval_recall_macro': 1.0, 'eval_runtime': 0.2535, 'eval_samples_per_second': 780.967, 'eval_steps_per_second': 51.276, 'epoch': 2.0}\n",
      "{'loss': 0.0026, 'learning_rate': 3.4666666666666672e-06, 'epoch': 2.5}\n",
      "{'loss': 0.0023, 'learning_rate': 1.3333333333333336e-07, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c815d7197c41c6893b7965f6a75fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0015802672132849693, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_precision_macro': 1.0, 'eval_recall_macro': 1.0, 'eval_runtime': 0.2051, 'eval_samples_per_second': 965.152, 'eval_steps_per_second': 63.369, 'epoch': 3.0}\n",
      "{'train_runtime': 66.2639, 'train_samples_per_second': 35.902, 'train_steps_per_second': 4.527, 'train_loss': 0.08328939239184062, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c61bbec25e045458fa0321a36215eb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold metrics: {'eval_loss': 0.0037644030526280403, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_precision_macro': 1.0, 'eval_recall_macro': 1.0, 'eval_runtime': 0.4191, 'eval_samples_per_second': 472.423, 'eval_steps_per_second': 31.018, 'epoch': 3.0}\n",
      "\n",
      "\n",
      "=== TRAIN FOLD 1 ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f607ebd581a456db7fd4d01f311906a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/793 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "566beba6140047f487e2a7bdc1570499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/198 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c1097e51a0483e9f248b4d37b0c031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/793 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d0913e5bbf457688503cff271cd56c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/198 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\_ JCAM 2010-2028\\_3_MASTERAI_UNI\\Ciclo4\\Tesis 2 Proyecto\\ProyectoClasificador\\ClasificadorsemanticoBETO\\beto_gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2630b4d0984c454281c8a941f278ce3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4827, 'learning_rate': 1.6800000000000002e-05, 'epoch': 0.5}\n",
      "{'loss': 0.026, 'learning_rate': 1.3466666666666668e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02f315db61544283a7d83ac93d5860a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.018651988357305527, 'eval_accuracy': 0.98989898989899, 'eval_f1_macro': 0.9902777777777778, 'eval_precision_macro': 0.9918032786885246, 'eval_recall_macro': 0.9891304347826086, 'eval_runtime': 0.2306, 'eval_samples_per_second': 858.788, 'eval_steps_per_second': 56.385, 'epoch': 1.0}\n",
      "{'loss': 0.016, 'learning_rate': 1.0133333333333335e-05, 'epoch': 1.5}\n",
      "{'loss': 0.0032, 'learning_rate': 6.800000000000001e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc7cd8d04cb34d2d90c5b58caf34e03f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0019352458184584975, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_precision_macro': 1.0, 'eval_recall_macro': 1.0, 'eval_runtime': 0.2188, 'eval_samples_per_second': 904.788, 'eval_steps_per_second': 59.405, 'epoch': 2.0}\n",
      "{'loss': 0.0026, 'learning_rate': 3.4666666666666672e-06, 'epoch': 2.5}\n",
      "{'loss': 0.0024, 'learning_rate': 1.3333333333333336e-07, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed4375e08e4404ea0a0d9c1cc8a672e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.001600400311872363, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_precision_macro': 1.0, 'eval_recall_macro': 1.0, 'eval_runtime': 0.2032, 'eval_samples_per_second': 974.323, 'eval_steps_per_second': 63.971, 'epoch': 3.0}\n",
      "{'train_runtime': 66.1755, 'train_samples_per_second': 35.95, 'train_steps_per_second': 4.533, 'train_loss': 0.08883576234181723, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c41ae377b5489398600c5fbb44b85e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold metrics: {'eval_loss': 0.0019352458184584975, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_precision_macro': 1.0, 'eval_recall_macro': 1.0, 'eval_runtime': 0.423, 'eval_samples_per_second': 468.062, 'eval_steps_per_second': 30.731, 'epoch': 3.0}\n",
      "\n",
      "\n",
      "=== TRAIN FOLD 2 ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b974dc5ab4e4a82b5f577d1ca44f3a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/793 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b5b0c0ea0742c49c6039bd2ab2d8ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/198 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87714e8ec36d4ad69d634f6e96d0a6f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/793 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd332cdc81d431794b262a438fe441d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/198 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\_ JCAM 2010-2028\\_3_MASTERAI_UNI\\Ciclo4\\Tesis 2 Proyecto\\ProyectoClasificador\\ClasificadorsemanticoBETO\\beto_gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de1fd4a252aa4e7d83c4328c37275ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4731, 'learning_rate': 1.6800000000000002e-05, 'epoch': 0.5}\n",
      "{'loss': 0.0142, 'learning_rate': 1.3466666666666668e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0099ba6c48fc41ebb345771cfcbb5322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04213862493634224, 'eval_accuracy': 0.98989898989899, 'eval_f1_macro': 0.9900779828940749, 'eval_precision_macro': 0.9906896551724138, 'eval_recall_macro': 0.989592094196804, 'eval_runtime': 0.2052, 'eval_samples_per_second': 965.037, 'eval_steps_per_second': 63.361, 'epoch': 1.0}\n",
      "{'loss': 0.0044, 'learning_rate': 1.0133333333333335e-05, 'epoch': 1.5}\n",
      "{'loss': 0.0031, 'learning_rate': 6.800000000000001e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3c6def1cba42a4b9daf64912994165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.042931824922561646, 'eval_accuracy': 0.98989898989899, 'eval_f1_macro': 0.9900779828940749, 'eval_precision_macro': 0.9906896551724138, 'eval_recall_macro': 0.989592094196804, 'eval_runtime': 0.212, 'eval_samples_per_second': 934.009, 'eval_steps_per_second': 61.324, 'epoch': 2.0}\n",
      "{'loss': 0.0025, 'learning_rate': 3.4666666666666672e-06, 'epoch': 2.5}\n",
      "{'loss': 0.0022, 'learning_rate': 1.3333333333333336e-07, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6167994678b94697867f49efce56a67b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03865697234869003, 'eval_accuracy': 0.9949494949494949, 'eval_f1_macro': 0.9953008344312693, 'eval_precision_macro': 0.995, 'eval_recall_macro': 0.9956896551724138, 'eval_runtime': 0.233, 'eval_samples_per_second': 849.611, 'eval_steps_per_second': 55.783, 'epoch': 3.0}\n",
      "{'train_runtime': 70.0093, 'train_samples_per_second': 33.981, 'train_steps_per_second': 4.285, 'train_loss': 0.08325882752736409, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b0ec844336b40db8154917db51c568d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold metrics: {'eval_loss': 0.03865697234869003, 'eval_accuracy': 0.9949494949494949, 'eval_f1_macro': 0.9953008344312693, 'eval_precision_macro': 0.995, 'eval_recall_macro': 0.9956896551724138, 'eval_runtime': 0.4279, 'eval_samples_per_second': 462.715, 'eval_steps_per_second': 30.38, 'epoch': 3.0}\n",
      "\n",
      "\n",
      "=== TRAIN FOLD 3 ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb53c38d8a7d48f3884d37df2003772a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92fcff13adb84dd69f2b865f5fc45df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/199 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1265c0d1a9a94d458e7c9ad8d22e1e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd110cbd30e49f09e5c14f68eacf255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/199 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\_ JCAM 2010-2028\\_3_MASTERAI_UNI\\Ciclo4\\Tesis 2 Proyecto\\ProyectoClasificador\\ClasificadorsemanticoBETO\\beto_gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9e02ca277745d6bbca90d5bff520ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/297 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4541, 'learning_rate': 1.6632996632996633e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320c84e85fab495481285c912e97b983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01670241169631481, 'eval_accuracy': 0.9949748743718593, 'eval_f1_macro': 0.9950862318142403, 'eval_precision_macro': 0.9948979591836735, 'eval_recall_macro': 0.9953703703703703, 'eval_runtime': 0.2262, 'eval_samples_per_second': 879.764, 'eval_steps_per_second': 57.472, 'epoch': 1.0}\n",
      "{'loss': 0.0487, 'learning_rate': 1.3400673400673401e-05, 'epoch': 1.01}\n",
      "{'loss': 0.0048, 'learning_rate': 1.0033670033670035e-05, 'epoch': 1.52}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b116bf74a54d3c96a897149bfd704e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.003856295021250844, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_precision_macro': 1.0, 'eval_recall_macro': 1.0, 'eval_runtime': 0.2257, 'eval_samples_per_second': 881.85, 'eval_steps_per_second': 57.608, 'epoch': 2.0}\n",
      "{'loss': 0.0043, 'learning_rate': 6.666666666666667e-06, 'epoch': 2.02}\n",
      "{'loss': 0.0042, 'learning_rate': 3.2996632996633e-06, 'epoch': 2.53}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25acec25d2f54ed89561504140f35c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0017929269233718514, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_precision_macro': 1.0, 'eval_recall_macro': 1.0, 'eval_runtime': 0.2643, 'eval_samples_per_second': 752.96, 'eval_steps_per_second': 49.188, 'epoch': 3.0}\n",
      "{'train_runtime': 61.5353, 'train_samples_per_second': 38.612, 'train_steps_per_second': 4.827, 'train_loss': 0.08724421925014919, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ccb8ed19a74a87afe36f6d9643e6c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold metrics: {'eval_loss': 0.003856295021250844, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_precision_macro': 1.0, 'eval_recall_macro': 1.0, 'eval_runtime': 0.3839, 'eval_samples_per_second': 518.298, 'eval_steps_per_second': 33.859, 'epoch': 3.0}\n",
      "\n",
      "\n",
      "=== TRAIN FOLD 4 ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a378fad823454ab968ff666c17d07b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/793 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c5641401b04d13add80d6a087cb561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/198 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5976ffec5784eb4a6cc779acdc7b6df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/793 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc0568deb52d4b52944066c7eb350496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/198 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\_ JCAM 2010-2028\\_3_MASTERAI_UNI\\Ciclo4\\Tesis 2 Proyecto\\ProyectoClasificador\\ClasificadorsemanticoBETO\\beto_gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb99da1b64b14f14b798e949716cd5ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4188, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.5}\n",
      "{'loss': 0.0573, 'learning_rate': 1.3466666666666668e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00981f6fcfd344d89dc809ec61b43878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.004045216832309961, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_precision_macro': 1.0, 'eval_recall_macro': 1.0, 'eval_runtime': 0.2462, 'eval_samples_per_second': 804.237, 'eval_steps_per_second': 52.803, 'epoch': 1.0}\n",
      "{'loss': 0.0044, 'learning_rate': 1.0133333333333335e-05, 'epoch': 1.5}\n",
      "{'loss': 0.0125, 'learning_rate': 6.800000000000001e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf6db660b6444758f927be8837c6c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0042310478165745735, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_precision_macro': 1.0, 'eval_recall_macro': 1.0, 'eval_runtime': 0.253, 'eval_samples_per_second': 782.561, 'eval_steps_per_second': 51.38, 'epoch': 2.0}\n",
      "{'loss': 0.0027, 'learning_rate': 3.4666666666666672e-06, 'epoch': 2.5}\n",
      "{'loss': 0.0022, 'learning_rate': 1.3333333333333336e-07, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc323add98514ee6bfee614fdbdcda6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0015061694430187345, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_precision_macro': 1.0, 'eval_recall_macro': 1.0, 'eval_runtime': 0.2149, 'eval_samples_per_second': 921.258, 'eval_steps_per_second': 60.487, 'epoch': 3.0}\n",
      "{'train_runtime': 61.7073, 'train_samples_per_second': 38.553, 'train_steps_per_second': 4.862, 'train_loss': 0.08299334287643433, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76727333c6a40ff8d0cab7442093386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold metrics: {'eval_loss': 0.004045216832309961, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_precision_macro': 1.0, 'eval_recall_macro': 1.0, 'eval_runtime': 0.2091, 'eval_samples_per_second': 947.0, 'eval_steps_per_second': 62.177, 'epoch': 3.0}\n",
      "\n",
      "\n",
      "=== SUMMARY ===\n",
      "     fold  f1_macro  accuracy  precision_macro  recall_macro\n",
      "0  fold_0  1.000000  1.000000            1.000       1.00000\n",
      "1  fold_1  1.000000  1.000000            1.000       1.00000\n",
      "2  fold_2  0.995301  0.994949            0.995       0.99569\n",
      "3  fold_3  1.000000  1.000000            1.000       1.00000\n",
      "4  fold_4  1.000000  1.000000            1.000       1.00000\n",
      "      f1_macro  accuracy  precision_macro  recall_macro\n",
      "mean  0.999060  0.998990         0.999000      0.999138\n",
      "std   0.002102  0.002259         0.002236      0.001928\n",
      "✅ Guardado resumen: ..\\models\\beto_kfold\\kfold_results_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# 2_fine_tuning_beto_kfold.ipynb - celda principal de entrenamiento K-Fold\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    set_seed\n",
    ")\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# -------------------- CONFIG --------------------\n",
    "SEED = 42\n",
    "MODEL_NAME = \"dccuchile/bert-base-spanish-wwm-cased\"   # BETO\n",
    "OUT_BASE = Path(\"../models/beto_kfold\")\n",
    "OUT_BASE.mkdir(parents=True, exist_ok=True)\n",
    "FOLDS_CSV = Path(\"../data/processed/clean_v2/folds/corpus_clean_v2_folds.csv\")\n",
    "N_EPOCHS = 3          # cambiar si quieres\n",
    "LR = 2e-5\n",
    "EVAL_STRATEGY = \"epoch\"\n",
    "SAVE_STRATEGY = \"epoch\"\n",
    "PER_DEVICE_TRAIN_BATCH_SIZE = 8   # ajustar por memoria GPU\n",
    "PER_DEVICE_EVAL_BATCH_SIZE = 16\n",
    "WEIGHT_DECAY = 0.01\n",
    "LOGGING_STEPS = 50\n",
    "\n",
    "# debug tip: para pruebas rápidas usa EPOCHS=1 y batch_size=8\n",
    "# --------------------------------------------------------\n",
    "\n",
    "set_seed(SEED)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# -------------------- CARGA DATA --------------------\n",
    "df_master = pd.read_csv(FOLDS_CSV, encoding=\"utf-8\")\n",
    "assert {\"text\",\"labels\",\"fold\"}.issubset(df_master.columns), df_master.columns\n",
    "\n",
    "# mapeos de etiquetas (asegura id2label / label2id constantes)\n",
    "labels_sorted = sorted(df_master[\"labels\"].unique().tolist())\n",
    "label2id = {str(l): int(l) for l in labels_sorted}   # aquí las ids ya son numéricas\n",
    "id2label = {int(l): str(l) for l in labels_sorted}\n",
    "num_labels = len(labels_sorted)\n",
    "print(\"num_labels:\", num_labels, \"label2id:\", label2id)\n",
    "\n",
    "# -------------------- TOKENIZER y COLLATOR --------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# tokenization helper\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True, padding=False, max_length=256)\n",
    "\n",
    "# -------------------- METRICAS --------------------\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    f1_mac = f1_score(labels, preds, average=\"macro\", zero_division=0)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"macro\", zero_division=0)\n",
    "    rec = recall_score(labels, preds, average=\"macro\", zero_division=0)\n",
    "    return {\"accuracy\": acc, \"f1_macro\": f1_mac, \"precision_macro\": prec, \"recall_macro\": rec}\n",
    "\n",
    "# -------------------- FUNCION ENTRENAR POR FOLD --------------------\n",
    "def train_one_fold(fold_id):\n",
    "    print(f\"\\n\\n=== TRAIN FOLD {fold_id} ===\")\n",
    "    out_dir = OUT_BASE / f\"fold{fold_id}\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    train_df = df_master[df_master[\"fold\"] != fold_id][[\"text\",\"labels\"]].reset_index(drop=True)\n",
    "    val_df = df_master[df_master[\"fold\"] == fold_id][[\"text\",\"labels\"]].reset_index(drop=True)\n",
    "\n",
    "    # datasets HuggingFace\n",
    "    ds_train = Dataset.from_pandas(train_df)\n",
    "    ds_val = Dataset.from_pandas(val_df)\n",
    "\n",
    "    ds_train = ds_train.map(lambda x: {\"labels\": int(x[\"labels\"])}, remove_columns=[])  # ensure int\n",
    "    ds_val = ds_val.map(lambda x: {\"labels\": int(x[\"labels\"])}, remove_columns=[])\n",
    "\n",
    "    ds_train = ds_train.map(tokenize_batch, batched=True, batch_size=64)\n",
    "    ds_val = ds_val.map(tokenize_batch, batched=True, batch_size=64)\n",
    "\n",
    "    ds_train.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
    "    ds_val.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
    "\n",
    "    # load model fresh for each fold\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        num_labels=num_labels,\n",
    "        id2label=id2label,\n",
    "        label2id=label2id\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=str(out_dir),\n",
    "        evaluation_strategy=EVAL_STRATEGY,\n",
    "        save_strategy=SAVE_STRATEGY,\n",
    "        learning_rate=LR,\n",
    "        per_device_train_batch_size=PER_DEVICE_TRAIN_BATCH_SIZE,\n",
    "        per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH_SIZE,\n",
    "        num_train_epochs=N_EPOCHS,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        logging_strategy=\"steps\",\n",
    "        logging_steps=LOGGING_STEPS,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1_macro\",\n",
    "        greater_is_better=True,\n",
    "        save_total_limit=2,\n",
    "        seed=SEED,\n",
    "        fp16=torch.cuda.is_available(),   # usa mixed precision si hay GPU\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=ds_train,\n",
    "        eval_dataset=ds_val,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    # Entrenar\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluar final y guardar métricas\n",
    "    metrics = trainer.evaluate(ds_val)\n",
    "    print(\"Fold metrics:\", metrics)\n",
    "\n",
    "    # guardar métricas por fold en JSON y guardar el mejor checkpoint\n",
    "    (out_dir / \"metrics_fold.json\").write_text(json.dumps(metrics, default=str))\n",
    "    trainer.save_model(str(out_dir / \"best_model\"))\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# -------------------- LOOP 5-FOLD --------------------\n",
    "import json\n",
    "results = {}\n",
    "for k in sorted(df_master[\"fold\"].unique()):\n",
    "    # opcional: limpiar cache CUDA entre folds\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    metrics = train_one_fold(int(k))\n",
    "    results[f\"fold_{k}\"] = metrics\n",
    "\n",
    "# -------------------- RESUMEN --------------------\n",
    "# Construye dataframe con métricas clave por fold\n",
    "rows = []\n",
    "for fold, m in results.items():\n",
    "    rows.append({\n",
    "        \"fold\": fold,\n",
    "        \"f1_macro\": m.get(\"eval_f1_macro\", m.get(\"f1_macro\", None)),\n",
    "        \"accuracy\": m.get(\"eval_accuracy\", m.get(\"accuracy\", None)),\n",
    "        \"precision_macro\": m.get(\"eval_precision_macro\", m.get(\"precision_macro\", None)),\n",
    "        \"recall_macro\": m.get(\"eval_recall_macro\", m.get(\"recall_macro\", None))\n",
    "    })\n",
    "res_df = pd.DataFrame(rows)\n",
    "res_df[[\"f1_macro\",\"accuracy\",\"precision_macro\",\"recall_macro\"]] = res_df[[\"f1_macro\",\"accuracy\",\"precision_macro\",\"recall_macro\"]].astype(float)\n",
    "summary = res_df.describe().loc[[\"mean\",\"std\"]]\n",
    "print(\"\\n\\n=== SUMMARY ===\")\n",
    "print(res_df)\n",
    "print(summary)\n",
    "\n",
    "# guardar CSV resumen\n",
    "csv_out = OUT_BASE / \"kfold_results_summary.csv\"\n",
    "res_df.to_csv(csv_out, index=False)\n",
    "print(\"✅ Guardado resumen:\", csv_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9d857e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "num_labels: 4 labels: [0, 1, 2, 3]\n",
      "\n",
      "\n",
      "--- TRAIN FOLD 0 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ee549494a748e8ad204bfeefdf0c9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/793 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a69a530f3674c07aaefa96005f02a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/198 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc087e9698f4c2ab3797bc80fbef627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4661, 'learning_rate': 1.6733333333333335e-05, 'epoch': 0.5}\n",
      "{'loss': 0.0202, 'learning_rate': 1.3466666666666668e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158fc5c859084f75b2c950bd34e701db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0037641332019120455, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_precision_macro': 1.0, 'eval_recall_macro': 1.0, 'eval_runtime': 0.178, 'eval_samples_per_second': 1112.419, 'eval_steps_per_second': 39.328, 'epoch': 1.0}\n",
      "{'loss': 0.0049, 'learning_rate': 1.0133333333333335e-05, 'epoch': 1.5}\n",
      "{'loss': 0.0036, 'learning_rate': 6.800000000000001e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bebc6106638943c4af48c003c159b0ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0018960441229864955, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_precision_macro': 1.0, 'eval_recall_macro': 1.0, 'eval_runtime': 0.1922, 'eval_samples_per_second': 1030.141, 'eval_steps_per_second': 36.419, 'epoch': 2.0}\n",
      "{'loss': 0.0026, 'learning_rate': 3.4666666666666672e-06, 'epoch': 2.5}\n",
      "{'loss': 0.0023, 'learning_rate': 1.3333333333333336e-07, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4f630e7b6a4545a37874d5499c04a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0015802816487848759, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_precision_macro': 1.0, 'eval_recall_macro': 1.0, 'eval_runtime': 0.1579, 'eval_samples_per_second': 1253.823, 'eval_steps_per_second': 44.327, 'epoch': 3.0}\n",
      "{'train_runtime': 63.3688, 'train_samples_per_second': 37.542, 'train_steps_per_second': 4.734, 'train_loss': 0.08328939239184062, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac822537a43742b6b200a7ff8632a657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold metrics: {'eval_loss': 0.0037641332019120455, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_precision_macro': 1.0, 'eval_recall_macro': 1.0, 'eval_runtime': 0.326, 'eval_samples_per_second': 607.347, 'eval_steps_per_second': 21.472, 'epoch': 3.0}\n",
      "\n",
      "\n",
      "--- TRAIN FOLD 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7674793651f42178a4ade6f27aa1043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/793 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99a39f4becb4a3e8d23a57190913db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/198 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b975603b53124647ba166c3acd111cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4827, 'learning_rate': 1.6800000000000002e-05, 'epoch': 0.5}\n",
      "{'loss': 0.026, 'learning_rate': 1.3466666666666668e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb3f1a6a43f47e3b48b1aef887cc9bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.018637211993336678, 'eval_accuracy': 0.98989898989899, 'eval_f1_macro': 0.9902777777777778, 'eval_precision_macro': 0.9918032786885246, 'eval_recall_macro': 0.9891304347826086, 'eval_runtime': 0.1799, 'eval_samples_per_second': 1100.87, 'eval_steps_per_second': 38.92, 'epoch': 1.0}\n",
      "{'loss': 0.016, 'learning_rate': 1.0133333333333335e-05, 'epoch': 1.5}\n",
      "{'loss': 0.0032, 'learning_rate': 6.800000000000001e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13502cceca2d4203a9516b3d69f3d59d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0019353951793164015, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_precision_macro': 1.0, 'eval_recall_macro': 1.0, 'eval_runtime': 0.1388, 'eval_samples_per_second': 1426.565, 'eval_steps_per_second': 50.434, 'epoch': 2.0}\n",
      "{'loss': 0.0026, 'learning_rate': 3.4666666666666672e-06, 'epoch': 2.5}\n",
      "{'loss': 0.0024, 'learning_rate': 1.3333333333333336e-07, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ffb590ce6844fba4d1a2edadaa0ff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0016005111392587423, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_precision_macro': 1.0, 'eval_recall_macro': 1.0, 'eval_runtime': 0.1628, 'eval_samples_per_second': 1216.152, 'eval_steps_per_second': 42.995, 'epoch': 3.0}\n",
      "{'train_runtime': 73.5472, 'train_samples_per_second': 32.347, 'train_steps_per_second': 4.079, 'train_loss': 0.08883576234181723, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb0466b7ae9f4f6991ce018fae31da55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold metrics: {'eval_loss': 0.0019353951793164015, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_precision_macro': 1.0, 'eval_recall_macro': 1.0, 'eval_runtime': 0.1608, 'eval_samples_per_second': 1231.239, 'eval_steps_per_second': 43.529, 'epoch': 3.0}\n",
      "\n",
      "\n",
      "--- TRAIN FOLD 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af42dcec0204048b6d9b2e5b4143a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/793 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a166b185fbe84c879c35e258cd4f5ba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/198 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae97bdf351534178b739d5edfbee1613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4731, 'learning_rate': 1.6800000000000002e-05, 'epoch': 0.5}\n",
      "{'loss': 0.0142, 'learning_rate': 1.3466666666666668e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef0925ce74540a28876b2c5c6a140d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0421612448990345, 'eval_accuracy': 0.98989898989899, 'eval_f1_macro': 0.9900779828940749, 'eval_precision_macro': 0.9906896551724138, 'eval_recall_macro': 0.989592094196804, 'eval_runtime': 0.151, 'eval_samples_per_second': 1311.345, 'eval_steps_per_second': 46.361, 'epoch': 1.0}\n",
      "{'loss': 0.0044, 'learning_rate': 1.0133333333333335e-05, 'epoch': 1.5}\n",
      "{'loss': 0.0031, 'learning_rate': 6.800000000000001e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef9b1913774a432897c9be5154b0a1a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.042926888912916183, 'eval_accuracy': 0.98989898989899, 'eval_f1_macro': 0.9900779828940749, 'eval_precision_macro': 0.9906896551724138, 'eval_recall_macro': 0.989592094196804, 'eval_runtime': 0.1482, 'eval_samples_per_second': 1336.477, 'eval_steps_per_second': 47.249, 'epoch': 2.0}\n",
      "{'loss': 0.0025, 'learning_rate': 3.4666666666666672e-06, 'epoch': 2.5}\n",
      "{'loss': 0.0022, 'learning_rate': 1.3333333333333336e-07, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e4539d38304779b64acae431212354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03865227475762367, 'eval_accuracy': 0.9949494949494949, 'eval_f1_macro': 0.9953008344312693, 'eval_precision_macro': 0.995, 'eval_recall_macro': 0.9956896551724138, 'eval_runtime': 0.156, 'eval_samples_per_second': 1269.591, 'eval_steps_per_second': 44.885, 'epoch': 3.0}\n",
      "{'train_runtime': 62.232, 'train_samples_per_second': 38.228, 'train_steps_per_second': 4.821, 'train_loss': 0.08325882752736409, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df543a0b24714e6e8b82c58075008400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold metrics: {'eval_loss': 0.03865227475762367, 'eval_accuracy': 0.9949494949494949, 'eval_f1_macro': 0.9953008344312693, 'eval_precision_macro': 0.995, 'eval_recall_macro': 0.9956896551724138, 'eval_runtime': 0.2919, 'eval_samples_per_second': 678.37, 'eval_steps_per_second': 23.983, 'epoch': 3.0}\n",
      "\n",
      "\n",
      "--- TRAIN FOLD 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d50e062542747b8987ccc9568691dda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc42ace872b4d5eb894c9256d0323df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/199 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2fd3598bed84e7398de8eaed522ff9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/297 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4541, 'learning_rate': 1.6632996632996633e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c7d833073b74e40b089010769e0b856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.016675373539328575, 'eval_accuracy': 0.9949748743718593, 'eval_f1_macro': 0.9950862318142403, 'eval_precision_macro': 0.9948979591836735, 'eval_recall_macro': 0.9953703703703703, 'eval_runtime': 0.1682, 'eval_samples_per_second': 1182.772, 'eval_steps_per_second': 41.605, 'epoch': 1.0}\n",
      "{'loss': 0.0487, 'learning_rate': 1.3400673400673401e-05, 'epoch': 1.01}\n",
      "{'loss': 0.0048, 'learning_rate': 1.0033670033670035e-05, 'epoch': 1.52}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1c5553de52430fbd11cfca2e97b1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.003854871727526188, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_precision_macro': 1.0, 'eval_recall_macro': 1.0, 'eval_runtime': 0.176, 'eval_samples_per_second': 1130.516, 'eval_steps_per_second': 39.767, 'epoch': 2.0}\n",
      "{'loss': 0.0043, 'learning_rate': 6.666666666666667e-06, 'epoch': 2.02}\n",
      "{'loss': 0.0042, 'learning_rate': 3.2996632996633e-06, 'epoch': 2.53}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "346228661b6f4c65a9f16cad069610b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0017921457765623927, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_precision_macro': 1.0, 'eval_recall_macro': 1.0, 'eval_runtime': 0.1682, 'eval_samples_per_second': 1183.333, 'eval_steps_per_second': 41.625, 'epoch': 3.0}\n",
      "{'train_runtime': 68.3352, 'train_samples_per_second': 34.77, 'train_steps_per_second': 4.346, 'train_loss': 0.08724421925014919, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69ab934d4014af6ac178d4adc6e102b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold metrics: {'eval_loss': 0.003854871727526188, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_precision_macro': 1.0, 'eval_recall_macro': 1.0, 'eval_runtime': 0.304, 'eval_samples_per_second': 654.602, 'eval_steps_per_second': 23.026, 'epoch': 3.0}\n",
      "\n",
      "\n",
      "--- TRAIN FOLD 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e35a623b38141f1b94a684fcefa652f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/793 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e2878b9ac6493eb870f0dd5e94ec65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/198 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3e2610dda64325b64892eb1dbe0610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4188, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.5}\n",
      "{'loss': 0.0573, 'learning_rate': 1.3466666666666668e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6143a46189a8418da5557790e0aebfc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0040450915694236755, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_precision_macro': 1.0, 'eval_recall_macro': 1.0, 'eval_runtime': 0.179, 'eval_samples_per_second': 1106.161, 'eval_steps_per_second': 39.107, 'epoch': 1.0}\n",
      "{'loss': 0.0044, 'learning_rate': 1.0133333333333335e-05, 'epoch': 1.5}\n",
      "{'loss': 0.0125, 'learning_rate': 6.800000000000001e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dfab987dab24f3ea30e6b80aaaa1f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.004231057595461607, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_precision_macro': 1.0, 'eval_recall_macro': 1.0, 'eval_runtime': 0.1481, 'eval_samples_per_second': 1337.039, 'eval_steps_per_second': 47.269, 'epoch': 2.0}\n",
      "{'loss': 0.0027, 'learning_rate': 3.4666666666666672e-06, 'epoch': 2.5}\n",
      "{'loss': 0.0022, 'learning_rate': 1.3333333333333336e-07, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c1359e900a4bd2be88f258cac6addf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.001506212865933776, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_precision_macro': 1.0, 'eval_recall_macro': 1.0, 'eval_runtime': 0.1466, 'eval_samples_per_second': 1350.353, 'eval_steps_per_second': 47.74, 'epoch': 3.0}\n",
      "{'train_runtime': 62.5302, 'train_samples_per_second': 38.046, 'train_steps_per_second': 4.798, 'train_loss': 0.08299334287643433, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ccd4d62d9be4e97a546c960ffc41f09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold metrics: {'eval_loss': 0.0040450915694236755, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_precision_macro': 1.0, 'eval_recall_macro': 1.0, 'eval_runtime': 0.3153, 'eval_samples_per_second': 628.048, 'eval_steps_per_second': 22.204, 'epoch': 3.0}\n",
      "✅ Guardado resumen: ..\\models\\beto_kfold\\kfold_results_summary.csv\n",
      "     fold  f1_macro  accuracy  precision_macro  recall_macro\n",
      "0  fold_0  1.000000  1.000000            1.000       1.00000\n",
      "1  fold_1  1.000000  1.000000            1.000       1.00000\n",
      "2  fold_2  0.995301  0.994949            0.995       0.99569\n",
      "3  fold_3  1.000000  1.000000            1.000       1.00000\n",
      "4  fold_4  1.000000  1.000000            1.000       1.00000\n"
     ]
    }
   ],
   "source": [
    "# CELDA C: K-Fold con BETO (con early stopping)\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, EarlyStoppingCallback, set_seed\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "set_seed(SEED)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "df_master = pd.read_csv(FOLDS_CSV, encoding=\"utf-8\")\n",
    "assert {\"text\",\"labels\",\"fold\"}.issubset(df_master.columns)\n",
    "\n",
    "labels_sorted = sorted(df_master[\"labels\"].unique().tolist())\n",
    "label2id = {str(l): int(l) for l in labels_sorted}\n",
    "id2label = {int(l): str(l) for l in labels_sorted}\n",
    "num_labels = len(labels_sorted)\n",
    "print(\"num_labels:\", num_labels, \"labels:\", labels_sorted)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True, padding=False, max_length=256)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1_macro\": f1_score(labels, preds, average=\"macro\", zero_division=0),\n",
    "        \"precision_macro\": precision_score(labels, preds, average=\"macro\", zero_division=0),\n",
    "        \"recall_macro\": recall_score(labels, preds, average=\"macro\", zero_division=0),\n",
    "    }\n",
    "\n",
    "results = {}\n",
    "for k in sorted(df_master[\"fold\"].unique()):\n",
    "    print(f\"\\n\\n--- TRAIN FOLD {k} ---\")\n",
    "    out_dir = OUT_BASE / f\"fold{k}\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    train_df = df_master[df_master[\"fold\"] != k][[\"text\",\"labels\"]].reset_index(drop=True)\n",
    "    val_df   = df_master[df_master[\"fold\"] == k][[\"text\",\"labels\"]].reset_index(drop=True)\n",
    "\n",
    "    ds_train = Dataset.from_pandas(train_df).map(tokenize_batch, batched=True, batch_size=64)\n",
    "    ds_val   = Dataset.from_pandas(val_df).map(tokenize_batch, batched=True, batch_size=64)\n",
    "\n",
    "    ds_train.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
    "    ds_val.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        num_labels=num_labels,\n",
    "        id2label=id2label,\n",
    "        label2id=label2id\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=str(out_dir),\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=LR,\n",
    "        per_device_train_batch_size=TRAIN_BS,\n",
    "        per_device_eval_batch_size=EVAL_BS,\n",
    "        num_train_epochs=N_EPOCHS,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        logging_strategy=\"steps\",\n",
    "        logging_steps=LOGGING_STEPS,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1_macro\",\n",
    "        greater_is_better=True,\n",
    "        save_total_limit=SAVE_TOTAL_LIMIT,\n",
    "        seed=SEED,\n",
    "        fp16=torch.cuda.is_available(),\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=ds_train,\n",
    "        eval_dataset=ds_val,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate(ds_val)\n",
    "    print(\"Fold metrics:\", metrics)\n",
    "\n",
    "    # guardar\n",
    "    (out_dir / \"metrics_fold.json\").write_text(json.dumps(metrics, default=str))\n",
    "    trainer.save_model(str(out_dir / \"best_model\"))\n",
    "    results[f\"fold_{k}\"] = {\n",
    "        \"f1_macro\": float(metrics.get(\"eval_f1_macro\", np.nan)),\n",
    "        \"accuracy\": float(metrics.get(\"eval_accuracy\", np.nan)),\n",
    "        \"precision_macro\": float(metrics.get(\"eval_precision_macro\", np.nan)),\n",
    "        \"recall_macro\": float(metrics.get(\"eval_recall_macro\", np.nan)),\n",
    "    }\n",
    "\n",
    "# resumen final\n",
    "res_df = pd.DataFrame.from_dict(results, orient=\"index\").reset_index().rename(columns={\"index\":\"fold\"})\n",
    "csv_out = OUT_BASE / \"kfold_results_summary.csv\"\n",
    "res_df.to_csv(csv_out, index=False)\n",
    "print(\"✅ Guardado resumen:\", csv_out)\n",
    "print(res_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b726ce",
   "metadata": {},
   "source": [
    "# validaciones post resultado de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c5a1c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 -> train: 793  val: 198\n",
      "\n",
      "--- Muestras train (5) ---\n",
      "['Habla de verdad y solo cuenta su parte', 'La fuerza del pueblo es más fuerte que cualquier crisis', 'Más del 60 % de los empleos creados en pandemia fueron informales', 'Se llena la boca de patria y vacía los bolsillos del Estado', 'Más de 50 000 escolares abandonaron clases tras la pandemia']\n",
      "\n",
      "--- Muestras val (5) ---\n",
      "['No hay fuerza más grande que la esperanza', '[PARTIDO] somos mayoría, [ADVERSARIO] son ruido', '[ADVERSARIO] confunden crítica con traición, [PARTIDO] sabemos que es deber', 'El acceso a internet rural apenas cubre el 25 % de los hogares', 'El 80 % de los trabajadores agrícolas no tiene contrato']\n",
      "\n",
      "Intersección exacta textos train∩val: 0\n"
     ]
    }
   ],
   "source": [
    "# DIAG 1: verificar tamaños y ejemplos crudos (antes de tokenizar)\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "PATH = Path(\"../data/processed/clean_v2/folds/corpus_clean_v2_folds.csv\")\n",
    "df = pd.read_csv(PATH, encoding=\"utf-8\")\n",
    "\n",
    "k = 0   # chequear el fold 0; repítelo por otros folds si quieres\n",
    "train_df = df[df[\"fold\"] != k].reset_index(drop=True)\n",
    "val_df   = df[df[\"fold\"] == k].reset_index(drop=True)\n",
    "\n",
    "print(\"Fold\", k, \"-> train:\", len(train_df), \" val:\", len(val_df))\n",
    "print(\"\\n--- Muestras train (5) ---\")\n",
    "print(train_df[\"text\"].head(5).to_list())\n",
    "print(\"\\n--- Muestras val (5) ---\")\n",
    "print(val_df[\"text\"].head(5).to_list())\n",
    "\n",
    "# chequear cuántos textos exactos se repiten (de nuevo)\n",
    "train_set = set(train_df[\"text\"].astype(str))\n",
    "val_set   = set(val_df[\"text\"].astype(str))\n",
    "print(\"\\nIntersección exacta textos train∩val:\", len(train_set & val_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34631220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hashes train: 793  hashes val: 198\n",
      "Intersección hashes tokenizados: 0\n"
     ]
    }
   ],
   "source": [
    "# DIAG 2: comparar hash de input_ids tokenizados (fold 0)\n",
    "from transformers import AutoTokenizer\n",
    "import hashlib, numpy as np\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\", use_fast=True)\n",
    "def hash_input_ids(texts, tokenizer):\n",
    "    hset = set()\n",
    "    for i in range(0, len(texts), 64):\n",
    "        batch = texts[i:i+64]\n",
    "        enc = tokenizer(batch, truncation=True, padding=False, max_length=256, return_tensors=\"np\")\n",
    "        for ids in enc[\"input_ids\"]:\n",
    "            h = hashlib.md5(ids.tobytes()).hexdigest()\n",
    "            hset.add(h)\n",
    "    return hset\n",
    "\n",
    "train_hashes = hash_input_ids(train_df[\"text\"].astype(str).tolist(), tokenizer)\n",
    "val_hashes   = hash_input_ids(val_df[\"text\"].astype(str).tolist(), tokenizer)\n",
    "print(\"Hashes train:\", len(train_hashes), \" hashes val:\", len(val_hashes))\n",
    "print(\"Intersección hashes tokenizados:\", len(train_hashes & val_hashes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28a756e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval manual accuracy: 1.0\n",
      "Eval manual f1_macro: 1.0\n"
     ]
    }
   ],
   "source": [
    "# DIAG 3: evaluar manualmente el best_model del fold 0 (sin Trainer)\n",
    "import torch, numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "model_dir = \"../models/beto_kfold/fold0/best_model\"   # ajusta si tu carpeta es distinta\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\", use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "val_texts = val_df[\"text\"].astype(str).tolist()\n",
    "val_labels = val_df[\"labels\"].astype(int).values\n",
    "\n",
    "bs = 32\n",
    "preds = []\n",
    "for i in range(0, len(val_texts), bs):\n",
    "    batch = val_texts[i:i+bs]\n",
    "    enc = tokenizer(batch, padding=True, truncation=True, max_length=256, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        out = model(**enc)\n",
    "        logits = out.logits.cpu().numpy()\n",
    "    preds.extend(np.argmax(logits, axis=1).tolist())\n",
    "\n",
    "print(\"Eval manual accuracy:\", accuracy_score(val_labels, preds))\n",
    "print(\"Eval manual f1_macro:\", f1_score(val_labels, preds, average=\"macro\", zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "491c2729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comprobando existencia: True\n",
      "Eval manual accuracy: 1.0\n",
      "Eval manual f1_macro: 1.0\n",
      "0 lab: 3 pred: 3 -> No hay fuerza más grande que la esperanza\n",
      "1 lab: 1 pred: 1 -> [PARTIDO] somos mayoría, [ADVERSARIO] son ruido\n",
      "2 lab: 1 pred: 1 -> [ADVERSARIO] confunden crítica con traición, [PARTIDO] sabemos que es deber\n",
      "3 lab: 2 pred: 2 -> El acceso a internet rural apenas cubre el 25 % de los hogares\n",
      "4 lab: 2 pred: 2 -> El 80 % de los trabajadores agrícolas no tiene contrato\n",
      "5 lab: 2 pred: 2 -> El déficit fiscal se redujo al 2,1 % del PBI en el último año\n",
      "6 lab: 2 pred: 2 -> La inversión pública regional cayó 14 % respecto al año anterior\n",
      "7 lab: 2 pred: 2 -> El 40 % de las familias peruanas vive sin acceso a alcantarillado\n",
      "8 lab: 1 pred: 1 -> [ADVERSARIO] nos llaman resentidos, [PARTIDO] los llamamos responsables\n",
      "9 lab: 2 pred: 2 -> La contaminación del aire en Lima excede tres veces los límites de la OMS\n"
     ]
    }
   ],
   "source": [
    "# DIAG 3: evaluar manualmente el best_model del fold 0 (sin Trainer)\n",
    "import torch, numpy as np, pandas as pd\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from pathlib import Path\n",
    "\n",
    "PATH = Path(\"../data/processed/clean_v2/folds/corpus_clean_v2_folds.csv\")\n",
    "df = pd.read_csv(PATH, encoding=\"utf-8\")\n",
    "k = 0\n",
    "val_df = df[df[\"fold\"]==k].reset_index(drop=True)\n",
    "\n",
    "model_dir = Path(\"../models/beto_kfold/fold0/best_model\")   # ajusta si tu carpeta es distinta\n",
    "print(\"Comprobando existencia:\", model_dir.exists())\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\", use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(str(model_dir)).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "val_texts = val_df[\"text\"].astype(str).tolist()\n",
    "val_labels = val_df[\"labels\"].astype(int).values\n",
    "\n",
    "bs = 32\n",
    "preds = []\n",
    "for i in range(0, len(val_texts), bs):\n",
    "    batch = val_texts[i:i+bs]\n",
    "    enc = tokenizer(batch, padding=True, truncation=True, max_length=256, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        out = model(**enc)\n",
    "        logits = out.logits.cpu().numpy()\n",
    "    preds.extend(np.argmax(logits, axis=1).tolist())\n",
    "\n",
    "print(\"Eval manual accuracy:\", accuracy_score(val_labels, preds))\n",
    "print(\"Eval manual f1_macro:\", f1_score(val_labels, preds, average=\"macro\", zero_division=0))\n",
    "\n",
    "# Muestra 10 ejemplos para inspección\n",
    "for i in range(min(10, len(val_texts))):\n",
    "    print(i, \"lab:\", val_labels[i], \"pred:\", preds[i], \"->\", val_texts[i][:180].replace(\"\\n\",\" \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac79f61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer args (sólo algunas claves):\n",
      "output_dir -> ..\\models\\beto_kfold\\fold4\n",
      "evaluation_strategy -> IntervalStrategy.EPOCH\n",
      "load_best_model_at_end -> True\n",
      "metric_for_best_model -> f1_macro\n",
      "save_strategy -> IntervalStrategy.EPOCH\n",
      "\n",
      "Eval dataset type: <class 'datasets.arrow_dataset.Dataset'>\n",
      "len(eval_dataset)= 198\n",
      "Ejemplo eval_dataset keys: ['labels', 'input_ids', 'attention_mask']\n",
      "Ejemplo labels[0]: tensor(2)\n",
      "input_ids len: 13\n"
     ]
    }
   ],
   "source": [
    "# DIAG 5: inspeccionar trainer.args y eval_dataset\n",
    "# Ejecuta esto **en la misma sesión** donde hayas creado trainer (o justo después de la training loop)\n",
    "print(\"Trainer args (sólo algunas claves):\")\n",
    "for k in [\"output_dir\",\"evaluation_strategy\",\"load_best_model_at_end\",\"metric_for_best_model\",\"save_strategy\"]:\n",
    "    print(k, \"->\", getattr(trainer.args, k, None))\n",
    "\n",
    "print(\"\\nEval dataset type:\", type(getattr(trainer, \"eval_dataset\", None)))\n",
    "try:\n",
    "    ed = trainer.eval_dataset\n",
    "    # si es Dataset, imprime su tamaño y primeras labels/texts (si tiene)\n",
    "    if hasattr(ed, \"__len__\"):\n",
    "        print(\"len(eval_dataset)=\", len(ed))\n",
    "    # si podemos, intentar extraer un ejemplo formateado\n",
    "    try:\n",
    "        sample = ed[0]\n",
    "        print(\"Ejemplo eval_dataset keys:\", list(sample.keys()))\n",
    "        if \"labels\" in sample:\n",
    "            print(\"Ejemplo labels[0]:\", sample[\"labels\"])\n",
    "        # print small sample of tokenized ids if present\n",
    "        if \"input_ids\" in sample:\n",
    "            print(\"input_ids len:\", len(sample[\"input_ids\"]))\n",
    "    except Exception as e:\n",
    "        print(\"No se pudo mostrar item de eval_dataset:\", e)\n",
    "except Exception as e:\n",
    "    print(\"Error accediendo a trainer.eval_dataset:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b10009d",
   "metadata": {},
   "source": [
    "\n",
    "## Evaluacion de los diagnostivos segundo nivel luego de estos resultados previos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed0cb0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apariciones de label names en texto (si hay): {}\n"
     ]
    }
   ],
   "source": [
    "# DIAG A: buscar label names dentro del texto\n",
    "import re, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "F = Path(\"../data/processed/clean_v2/folds/corpus_clean_v2_folds.csv\")\n",
    "df = pd.read_csv(F, encoding=\"utf-8\")\n",
    "# Si tienes labels_name en el DF, úsalo; si no, define nombres manualmente:\n",
    "if \"labels_name\" in df.columns:\n",
    "    label_names = sorted(df[\"labels_name\"].dropna().unique().tolist())\n",
    "else:\n",
    "    # ajusta estos a tus nombres reales (ej.: ad_hominem, logos, framing, retorica_vacia)\n",
    "    label_names = [\"ad_hominem\",\"logos\",\"framing\",\"retorica_vacia\",\"retorica_vacia\",\"retorica\",\"vacia\"]\n",
    "\n",
    "res = {}\n",
    "for name in label_names:\n",
    "    n = df[\"text\"].astype(str).str.contains(re.escape(name), case=False, na=False).sum()\n",
    "    if n>0:\n",
    "        res[name] = int(n)\n",
    "\n",
    "print(\"Apariciones de label names en texto (si hay):\", res)\n",
    "# Muestra ejemplos si hay\n",
    "for name,count in res.items():\n",
    "    print(f\"\\n=== Ejemplos con '{name}' ===\")\n",
    "    print(df[df[\"text\"].astype(str).str.contains(re.escape(name), case=False, na=False)][\"text\"].head(10).to_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "956c9c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textos que terminan con coma/espacio + dígito (ej. ', 0'): 0\n",
      "textos que terminan con coma + palabra (ej. ',ad_hominem'): 0\n"
     ]
    }
   ],
   "source": [
    "# DIAG B: buscar patrones de etiqueta numérica o coma+etiqueta al final\n",
    "import re, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "F = Path(\"../data/processed/clean_v2/folds/corpus_clean_v2_folds.csv\")\n",
    "df = pd.read_csv(F, encoding=\"utf-8\")\n",
    "\n",
    "# buscar textos que terminan con \", 0\" o \",0\" o \" , 0\" etc. (cualquier dígito de etiqueta)\n",
    "pattern_end_num = re.compile(r\"[,\\s]\\s*[0-9]\\s*$\")\n",
    "mask_end_num = df[\"text\"].astype(str).str.match(pattern_end_num)\n",
    "print(\"textos que terminan con coma/espacio + dígito (ej. ', 0'):\", mask_end_num.sum())\n",
    "if mask_end_num.sum()>0:\n",
    "    print(df[mask_end_num][\"text\"].head(10).to_list())\n",
    "\n",
    "# buscar patrones con coma + palabra (ej. ',ad_hominem') al final\n",
    "pattern_end_word = re.compile(r\",\\s*[A-Za-z_ñÑáéíóúÁÉÍÓÚ-]{3,}\\s*$\")\n",
    "mask_end_word = df[\"text\"].astype(str).str.match(pattern_end_word)\n",
    "print(\"textos que terminan con coma + palabra (ej. ',ad_hominem'):\", mask_end_word.sum())\n",
    "if mask_end_word.sum()>0:\n",
    "    print(df[mask_end_word][\"text\"].head(10).to_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "711454ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apariciones de tokens numéricos exactos (posible fuga): {0: 2, 1: 3, 2: 4, 3: 3}\n",
      "\n",
      "Ejemplos que contienen token '0':\n",
      "[{'text': 'El gasto en investigación científica es menor al 0,2 % del PBI', 'labels': 2}, {'text': 'El gasto en cultura representa menos del 0,1 % del presupuesto nacional', 'labels': 2}]\n",
      "\n",
      "Ejemplos que contienen token '1':\n",
      "[{'text': 'El déficit fiscal se redujo al 2,1 % del PBI en el último año', 'labels': 2}, {'text': 'El acceso a agua potable mejoró, pero aún falta cobertura en 1,2 millones de hogares', 'labels': 2}, {'text': 'El gasto en cultura representa menos del 0,1 % del presupuesto nacional', 'labels': 2}]\n",
      "\n",
      "Ejemplos que contienen token '2':\n",
      "[{'text': 'El PBI del país creció 2,5 % durante el último trimestre', 'labels': 2}, {'text': 'El déficit fiscal se redujo al 2,1 % del PBI en el último año', 'labels': 2}, {'text': 'El gasto en investigación científica es menor al 0,2 % del PBI', 'labels': 2}, {'text': 'El acceso a agua potable mejoró, pero aún falta cobertura en 1,2 millones de hogares', 'labels': 2}]\n",
      "\n",
      "Ejemplos que contienen token '3':\n",
      "[{'text': 'Las cifras de desnutrición infantil se redujeron en 3 puntos, pero aún son alarmantes', 'labels': 2}, {'text': 'El gasto en salud representa apenas el 3 % del PBI', 'labels': 2}, {'text': 'El 49% de los niños peruanos menores a 3 años tienen anemia', 'labels': 2}]\n"
     ]
    }
   ],
   "source": [
    "# DIAG C: buscar apariciones de tokens ' 0 ' ' 1 ' como token independiente\n",
    "import re, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "F = Path(\"../data/processed/clean_v2/folds/corpus_clean_v2_folds.csv\")\n",
    "df = pd.read_csv(F, encoding=\"utf-8\")\n",
    "counts = {}\n",
    "for lid in sorted(df[\"labels\"].unique()):\n",
    "    patt = rf\"(?<!\\d){re.escape(str(lid))}(?!\\d)\"   # digit not part of larger number\n",
    "    cnt = df[\"text\"].astype(str).str.contains(patt, regex=True, na=False, case=False).sum()\n",
    "    counts[int(lid)] = int(cnt)\n",
    "\n",
    "print(\"Apariciones de tokens numéricos exactos (posible fuga):\", counts)\n",
    "# mostrar ejemplos si hay\n",
    "for lid,cnt in counts.items():\n",
    "    if cnt>0:\n",
    "        print(f\"\\nEjemplos que contienen token '{lid}':\")\n",
    "        print(df[df[\"text\"].astype(str).str.contains(rf'(?<!\\d){lid}(?!\\d)', regex=True, na=False)][[\"text\",\"labels\"]].head(10).to_dict(orient=\"records\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c04e7e",
   "metadata": {},
   "source": [
    "A continuación 3 pruebas concretas y ordenadas que haz ahora (muy rápidas). Primero detectamos las palabras/strings que hay tokens/plantillas que permiten separar perfectamente las clases o que, en esa ejecución concreta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdc9060c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Label 0 — top tokens (peso, token) ===\n",
      "4.0122\tpromete\n",
      "3.5170\tpero\n",
      "3.2571\thabla\n",
      "3.2245\thabla de\n",
      "3.0500\tpredica\n",
      "2.5887\tdice\n",
      "2.0137\tpolítico\n",
      "1.9992\tque\n",
      "1.9792\tdice que\n",
      "1.7194\tel que\n",
      "1.4268\tquien\n",
      "1.3589\tsu\n",
      "1.0749\tcritica\n",
      "0.9995\tcomo\n",
      "0.9702\tvive\n",
      "0.9592\tgobierna\n",
      "0.9331\tsiempre\n",
      "0.9182\ttransparencia\n",
      "0.8989\tno\n",
      "0.8688\tal\n",
      "\n",
      "=== Label 1 — top tokens (peso, token) ===\n",
      "8.0542\tadversario\n",
      "7.3069\tpartido\n",
      "1.2397\tviven\n",
      "1.1766\tadversario se\n",
      "1.1245\tadversario viven\n",
      "0.9170\thablan\n",
      "0.8722\tpartido seguimos\n",
      "0.8722\tseguimos\n",
      "0.8387\tpartido la\n",
      "0.7823\tadversario hablan\n",
      "0.7645\thablan de\n",
      "0.7588\tllaman\n",
      "0.6950\tdesde\n",
      "0.6686\treparten\n",
      "0.6607\tpartido lo\n",
      "0.6415\ttenemos\n",
      "0.6326\tpartido sabemos\n",
      "0.6264\tlo\n",
      "0.6222\tcreen\n",
      "0.6108\tvivimos\n",
      "\n",
      "=== Label 2 — top tokens (peso, token) ===\n",
      "4.2876\tde\n",
      "3.5847\tde los\n",
      "2.9911\tel\n",
      "2.1248\tde las\n",
      "2.0819\tlos\n",
      "2.0003\tlas\n",
      "1.5050\tmás de\n",
      "1.3286\ten\n",
      "1.2587\tdel\n",
      "1.1785\trurales\n",
      "1.0954\t40\n",
      "1.0760\t60\n",
      "1.0295\tel 40\n",
      "0.9861\t70\n",
      "0.9821\tmás\n",
      "0.9616\taño\n",
      "0.9575\t30\n",
      "0.9560\t70 de\n",
      "0.9536\tnacional\n",
      "0.9443\t25\n",
      "\n",
      "=== Label 3 — top tokens (peso, token) ===\n",
      "2.9229\tperú\n",
      "2.1944\tel perú\n",
      "1.9162\tes\n",
      "1.8395\tsomos\n",
      "1.7857\tesperanza\n",
      "1.7497\tnuestra\n",
      "1.7351\tla\n",
      "1.7173\tcambio\n",
      "1.6901\tserá\n",
      "1.6487\tel cambio\n",
      "1.5697\tjuntos\n",
      "1.4530\tfuturo\n",
      "1.4409\thoy\n",
      "1.2815\tun\n",
      "1.2532\tnada\n",
      "1.2421\tfe\n",
      "1.2361\thistoria\n",
      "1.1851\testá\n",
      "1.1488\tpueblo\n",
      "1.1323\tnuestro\n",
      "\n",
      "Guardado top tokens en: ..\\logs\\top_tokens_by_label.csv\n"
     ]
    }
   ],
   "source": [
    "# TOP TOKENS por clase (TF-IDF + LogisticRegression entrenado en todo df)\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "FOLDS = Path(\"../data/processed/clean_v2/folds/corpus_clean_v2_folds.csv\")\n",
    "df = pd.read_csv(FOLDS, encoding=\"utf-8\")\n",
    "texts = df[\"text\"].astype(str).tolist()\n",
    "y = df[\"labels\"].astype(int).values\n",
    "\n",
    "vec = TfidfVectorizer(max_features=15000, ngram_range=(1,2), min_df=2)\n",
    "X = vec.fit_transform(texts)\n",
    "vocab = np.array(vec.get_feature_names_out())\n",
    "\n",
    "# Entrenar LR (one-vs-rest)\n",
    "clf = LogisticRegression(max_iter=5000, solver=\"liblinear\", multi_class=\"ovr\")\n",
    "clf.fit(X, y)\n",
    "\n",
    "def top_tokens_for_class(clf, vocab, class_label, topn=20):\n",
    "    \"\"\"\n",
    "    Devuelve (tokens_top, weights_top) para la clase con etiqueta class_label (no índice).\n",
    "    Maneja mapeo correcto entre label -> posición en clf.classes_.\n",
    "    \"\"\"\n",
    "    # ubica la posición real de la clase en clf.classes_\n",
    "    classes = list(clf.classes_)\n",
    "    if class_label not in classes:\n",
    "        raise ValueError(f\"label {class_label} not in trained classifier classes: {classes}\")\n",
    "    pos = classes.index(class_label)\n",
    "    coef = clf.coef_[pos]  # esto debe ser 1D array (n_features,)\n",
    "    top_idx = np.argsort(coef)[-topn:][::-1]\n",
    "    return vocab[top_idx], coef[top_idx]\n",
    "\n",
    "# imprimir top 20 por cada clase encontrada en el df\n",
    "labels_sorted = sorted(df[\"labels\"].unique())\n",
    "for lab in labels_sorted:\n",
    "    toks, w = top_tokens_for_class(clf, vocab, lab, topn=20)\n",
    "    print(f\"\\n=== Label {lab} — top tokens (peso, token) ===\")\n",
    "    for tok_i, wt in zip(toks, w):\n",
    "        # aseguramos convertir el peso a float de manera segura\n",
    "        wt_float = float(np.asarray(wt).item())\n",
    "        print(f\"{wt_float:.4f}\\t{tok_i}\")\n",
    "\n",
    "# guardar resultado completo (top 50 por clase) en CSV\n",
    "rows=[]\n",
    "for lab in labels_sorted:\n",
    "    toks, w = top_tokens_for_class(clf, vocab, lab, topn=50)\n",
    "    for tok_i, wt in zip(toks, w):\n",
    "        rows.append({\"label\": int(lab), \"token\": str(tok_i), \"weight\": float(np.asarray(wt).item())})\n",
    "\n",
    "out = Path(\"../logs/top_tokens_by_label.csv\")\n",
    "pd.DataFrame(rows).to_csv(out, index=False, encoding=\"utf-8\")\n",
    "print(\"\\nGuardado top tokens en:\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04b1f2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número tokens a enmascarar: 120\n",
      "Ejemplos: ['adversario', 'partido', 'de', 'promete', 'de los', 'pero', 'habla', 'habla de', 'predica', 'el', 'perú', 'dice', 'el perú', 'de las', 'los', 'político', 'las', 'que', 'dice que', 'es', 'somos', 'esperanza', 'nuestra', 'la', 'el que', 'cambio', 'será', 'el cambio', 'juntos', 'más de', 'futuro', 'hoy', 'quien', 'su', 'en', 'un', 'del', 'nada', 'fe', 'viven']\n",
      "LR masked F1-macro por fold: [0.8474 0.8648 0.8475 0.8012 0.7954] mean: 0.8313\n"
     ]
    }
   ],
   "source": [
    "# 1) Construir lista de tokens a enmascarar y evaluar LR (5-fold CV)\n",
    "import re, pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "# lee top tokens guardados\n",
    "topdf = pd.read_csv(\"../logs/top_tokens_by_label.csv\", encoding=\"utf-8\")\n",
    "# toma top N por label (ej. 30)\n",
    "N=30\n",
    "cands = topdf.sort_values(\"weight\", ascending=False).groupby(\"label\").head(N)[\"token\"].unique().tolist()\n",
    "print(\"Número tokens a enmascarar:\", len(cands))\n",
    "print(\"Ejemplos:\", cands[:40])\n",
    "\n",
    "# función que enmascara tokens (word-boundary, case-insensitive)\n",
    "def mask_tokens(s, tokens):\n",
    "    s0 = \" \" + str(s) + \" \"\n",
    "    for t in tokens:\n",
    "        # crear patrón de palabra (escapado), caso-insensible\n",
    "        pat = re.compile(r\"(?i)\\b\" + re.escape(t) + r\"\\b\")\n",
    "        s0 = pat.sub(\" <MASK> \", s0)\n",
    "    return \" \".join(s0.split())\n",
    "\n",
    "# cargar dataset folds maestro\n",
    "df = pd.read_csv(\"../data/processed/clean_v2/folds/corpus_clean_v2_folds.csv\", encoding=\"utf-8\")\n",
    "df[\"text_masked\"] = df[\"text\"].astype(str).apply(lambda x: mask_tokens(x, cands))\n",
    "\n",
    "# Vectorizar y cross-val\n",
    "vec = TfidfVectorizer(max_features=8000, ngram_range=(1,2), min_df=2)\n",
    "X_masked = vec.fit_transform(df[\"text_masked\"].tolist())\n",
    "y = df[\"labels\"].astype(int).values\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "clf = LogisticRegression(max_iter=5000, multi_class=\"ovr\", solver=\"liblinear\")\n",
    "scores_masked = cross_val_score(clf, X_masked, y, cv=skf, scoring=\"f1_macro\")\n",
    "print(\"LR masked F1-macro por fold:\", np.round(scores_masked,4), \"mean:\", round(scores_masked.mean(),4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a08163e",
   "metadata": {},
   "source": [
    "🧠 Interpretación\n",
    "\n",
    "Tu modelo base (TF-IDF + LR) antes del enmascarado estaba probablemente en torno a 0.97–0.99 de F1-macro, y al quitar solo 120 tokens frecuentes (palabras y frases cortas), cae a 0.83.\n",
    "\n",
    "➡️ Eso significa que casi 15-17 % de su poder predictivo venía de “atajos léxicos” (palabras que se repiten sistemáticamente por clase, como “ellos”, “nosotros”, “Perú”, “promete”, “más de”).\n",
    "\n",
    "➡️ En otras palabras, el modelo no estaba generalizando realmente el sentido, sino asociando ciertos marcadores con clases.\n",
    "\n",
    "📊 Qué implica esto\n",
    "\n",
    "Dataset aún útil, pero debe refinarse para eliminar esos artefactos antes de seguir fine-tuning con BETO.\n",
    "\n",
    "Si no se corrige, BETO aprenderá las mismas correlaciones y producirá F1≈1 artificial.\n",
    "\n",
    "La caída de 0.83 sigue mostrando que hay señal semántica real, solo que más delgada, lo que es bueno: el modelo aún distingue estilos, pero sin trampas léxicas bajará algo más la métrica y subirá la robustez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2edd1ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado dataset normalizado.\n"
     ]
    }
   ],
   "source": [
    "import re, pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/processed/clean_v2/folds/corpus_clean_v2_folds.csv\", encoding=\"utf-8\")\n",
    "\n",
    "def normalize_numbers(text):\n",
    "    s = str(text)\n",
    "    s = re.sub(r\"\\d+(\\,\\d+)?\\s*%\", \" <PCT> \", s)\n",
    "    s = re.sub(r\"\\d+(\\,\\d+)?\", \" <NUM> \", s)\n",
    "    return \" \".join(s.split())\n",
    "\n",
    "df[\"text_norm\"] = df[\"text\"].apply(normalize_numbers)\n",
    "df.to_csv(\"../data/processed/clean_v2/folds/corpus_clean_v2_norm.csv\", index=False)\n",
    "print(\"Guardado dataset normalizado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b72415",
   "metadata": {},
   "source": [
    "Hacemos TF-IDF sobre text_norm, entrena un LogisticRegression con 5-fold Stratified CV y muestra F1-macro por fold y la media."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beto_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
