# Sistema Clasificador BETO Fine-Tuned para AnÃ¡lisis RetÃ³rico en Frases PolÃ­ticas (Ad-hominem, Framing, LÃ³gica y RetÃ³rica VacÃ­a) â€“ VersiÃ³n 3.0

## ğŸ§© ActualizaciÃ³n V3.0 â€” Pipeline de Datos y Entrenamiento

Esta versiÃ³n consolida un pipeline experimental mÃ¡s sÃ³lido y reproducible para la
clasificaciÃ³n automÃ¡tica de estrategias retÃ³ricas en frases polÃ­ticas en espaÃ±ol.

Principales cambios respecto a versiones anteriores:

- **DepuraciÃ³n exhaustiva del corpus**
  - NormalizaciÃ³n de texto y correcciÃ³n de problemas de codificaciÃ³n.
  - EliminaciÃ³n de duplicados y casi duplicados.
  - Enmascarado de nombres propios y actores polÃ­ticos mediante tokens neutros
    (p. ej., `[POLITICO]`, `[PARTIDO]`) para reducir el sobreajuste a figuras
    especÃ­ficas.

- **Particionado sin fuga de informaciÃ³n**
  - AsignaciÃ³n de un `group_id` para agrupar frases similares o provenientes de
    la misma fuente.
  - GeneraciÃ³n de 5 folds con `StratifiedGroupKFold`, garantizando:
    - estratificaciÃ³n por clase (mismas proporciones de etiquetas en cada fold);
    - no mezclar frases del mismo grupo entre entrenamiento y prueba.

- **ComparaciÃ³n clara entre modelos**
  - **Baseline clÃ¡sico:** TF-IDF + RegresiÃ³n LogÃ­stica multinomial.
  - **Modelo propuesto:** BETO fine-tuned como clasificador de 4 etiquetas.

- **EvaluaciÃ³n rigurosa**
  - ValidaciÃ³n cruzada en 5 folds sobre el corpus depurado.
  - Hold-out interno (Fold 4) para anÃ¡lisis detallado.
  - Hold-out externo (â€œhumanoâ€): frases inÃ©ditas, redactadas manualmente.
  - MÃ©tricas: Accuracy, F1-macro, matriz de confusiÃ³n e inspecciÃ³n de errores.

**Usuarios expertos asociados al proyecto**

- Elizabeth RamÃ­rez (periodista)  
- Jim Delgado (politÃ³logo, jefe de prensa Antauro Humala)

Los resultados muestran una separaciÃ³n muy nÃ­tida entre las clases retÃ³ricas
(Ad-hominem, Framing binario, LÃ³gica/Logos y RetÃ³rica vacÃ­a), sin evidencia de
sobreajuste por duplicidad de muestras ni fuga de informaciÃ³n entre entrenamiento
y prueba.

---

## ğŸ“‚ Estructura del repositorio

```text
.
â”œâ”€ data/
â”‚  â”œâ”€ processed/
â”‚  â”‚  â”œâ”€ corpus_clean_v3_folds.csv   # corpus depurado con etiquetas, group_id y fold
â”‚  â”‚  â””â”€ holdout_humano.csv          # frases inÃ©ditas para evaluaciÃ³n externa
â”‚  â””â”€ raw/                            # datos sin procesar (no versionados en git)
â”œâ”€ models/
â”‚  â””â”€ beto_v3_final_fold0/           # modelo BETO fine-tuned + tokenizer
â”œâ”€ notebooks/
â”‚  â”œâ”€ 1_depurando_dataset_v3.ipynb
â”‚  â”œâ”€ 2_baseline_tfidf_lr_v3.ipynb
â”‚  â”œâ”€ 3_fine_tuning_v3.ipynb
â”‚  â”œâ”€ 4_inferencia_beto_v3.ipynb
â”‚  â”œâ”€ 5_analisis_resultados_beto_v3.ipynb
â”‚  â””â”€ 6_slices_analisis_beto_v3.ipynb
â”œâ”€ src/
â”‚  â”œâ”€ web/         # prototipo web / frontend (Flask o similar)
â”‚  â””â”€ beto_gpu/    # cÃ³digo y documentaciÃ³n relacionados al entrenamiento en GPU
â”œâ”€ logs/           # mÃ©tricas y registros de entrenamiento/validaciÃ³n
â””â”€ README.md       # este documento
