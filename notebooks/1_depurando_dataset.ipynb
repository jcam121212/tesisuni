{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bfc5747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Estructura OK | Filas: 1000\n",
      "Distribuci√≥n: Counter({0: 250, 3: 250, 2: 250, 1: 250})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ese candidato solo sabe hablar, pero nunca ha ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quienes nos critican desde Lima no entienden l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Habla de moral, pero no puede explicar de qu√© ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ese congresista cambi√≥ de partido m√°s veces qu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Siempre promete cambios, pero ni siquiera camb...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0  Ese candidato solo sabe hablar, pero nunca ha ...       0\n",
       "1  Quienes nos critican desde Lima no entienden l...       0\n",
       "2  Habla de moral, pero no puede explicar de qu√© ...       0\n",
       "3  Ese congresista cambi√≥ de partido m√°s veces qu...       0\n",
       "4  Siempre promete cambios, pero ni siquiera camb...       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re, hashlib\n",
    "\n",
    "PATH = Path(\"../data/processed/corpus_politico_codificado_utf8.csv\")\n",
    "\n",
    "# Leer el archivo\n",
    "df = pd.read_csv(PATH, encoding=\"utf-8\", engine=\"python\")\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "# ‚úÖ Ajuste para tu dataset\n",
    "if set(df.columns) == {\"texto\",\"etiqueta\"}:\n",
    "    df.rename(columns={\"texto\":\"text\",\"etiqueta\":\"labels\"}, inplace=True)\n",
    "\n",
    "elif set(df.columns) >= {\"text\",\"labels_name\",\"labels\"}:\n",
    "    df = df[[\"text\",\"labels\"]]\n",
    "\n",
    "elif set(df.columns) == {\"text\",\"labels\"}:\n",
    "    pass\n",
    "\n",
    "else:\n",
    "    raise AssertionError(f\"Encabezado inesperado: {list(df.columns)}. Debe tener ['texto','etiqueta'] o ['text','labels'].\")\n",
    "\n",
    "# Convertir tipo de datos\n",
    "df[\"text\"] = df[\"text\"].astype(str).str.strip()\n",
    "df[\"labels\"] = df[\"labels\"].astype(str).str.strip()\n",
    "\n",
    "# Mapear etiquetas de texto a n√∫mero si hace falta\n",
    "if pd.api.types.is_string_dtype(df[\"labels\"]):\n",
    "    # si son textos como 'logos' o 'ad_hominem'\n",
    "    if df[\"labels\"].str.isalpha().any():\n",
    "        etiquetas = sorted(df[\"labels\"].unique())\n",
    "        mapa = {etq:i for i,etq in enumerate(etiquetas)}\n",
    "        df[\"labels\"] = df[\"labels\"].map(mapa)\n",
    "        print(\"üìò Mapeo de etiquetas:\", mapa)\n",
    "    else:\n",
    "        # si ya son '0', '1', '2', '3' pero en string\n",
    "        df[\"labels\"] = df[\"labels\"].astype(int)\n",
    "\n",
    "\n",
    "df[\"labels\"] = df[\"labels\"].astype(int)\n",
    "\n",
    "print(\"‚úÖ Estructura OK | Filas:\", len(df))\n",
    "print(\"Distribuci√≥n:\", Counter(df[\"labels\"]))\n",
    "display(df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35ca7a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 2 1]\n"
     ]
    }
   ],
   "source": [
    "print(df[\"labels\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccbe9fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Duplicados exactos eliminados: 6 | Quedan: 994\n",
      "üîç Casi-duplicados detectados: 994\n",
      "‚úÖ Dataset final sin duplicados: 0 filas\n",
      "üíæ Guardado en: ..\\data\\processed\\clean_v2\\corpus_politico_codificado_utf8_clean_v2.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np, re\n",
    "\n",
    "# --- 1. Normalizaci√≥n b√°sica (acentos, espacios, s√≠mbolos) ---\n",
    "def normalize_text(s: str) -> str:\n",
    "    s = str(s).lower().strip()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    s = re.sub(r\"[\\\"‚Äú‚Äù‚Äò‚Äô]+\", \"\", s)\n",
    "    s = re.sub(r\"[^\\w\\s√°√©√≠√≥√∫√º√±]\", \"\", s)\n",
    "    return s\n",
    "\n",
    "df[\"norm_text\"] = df[\"text\"].apply(normalize_text)\n",
    "\n",
    "# --- 2. Duplicados exactos ---\n",
    "before = len(df)\n",
    "df = df.drop_duplicates(subset=[\"norm_text\",\"labels\"]).reset_index(drop=True)\n",
    "print(f\"üßπ Duplicados exactos eliminados: {before - len(df)} | Quedan: {len(df)}\")\n",
    "\n",
    "# --- 3. Casi-duplicados (similitud > 0.9) ---\n",
    "tfidf = TfidfVectorizer(min_df=1, max_features=5000).fit_transform(df[\"norm_text\"])\n",
    "sim = cosine_similarity(tfidf)\n",
    "\n",
    "mask = np.triu(np.ones(sim.shape), k=1).astype(bool)\n",
    "pairs = np.argwhere(sim > 0.9)\n",
    "keep = set()\n",
    "for i,j in pairs:\n",
    "    if i not in keep and j not in keep:\n",
    "        keep.add(j)  # elimina la segunda\n",
    "\n",
    "print(f\"üîç Casi-duplicados detectados: {len(keep)}\")\n",
    "\n",
    "df_clean = df.drop(list(keep)).reset_index(drop=True)\n",
    "print(f\"‚úÖ Dataset final sin duplicados: {len(df_clean)} filas\")\n",
    "\n",
    "# --- 4. Guardado ---\n",
    "out = Path(\"../data/processed/clean_v2/corpus_politico_codificado_utf8_clean_v2.csv\")\n",
    "out.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_clean[[\"text\",\"labels\"]].to_csv(out, index=False, encoding=\"utf-8\")\n",
    "print(\"üíæ Guardado en:\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e48e5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Casi-duplicados detectados: 4\n",
      "‚úÖ Dataset final sin duplicados: 990 filas\n",
      "üíæ Guardado en: ..\\data\\processed\\clean_v2\\corpus_politico_codificado_utf8_clean_v2.csv\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Casi-duplicados (similitud > 0.95) ---\n",
    "tfidf = TfidfVectorizer(min_df=1, max_features=5000).fit_transform(df[\"norm_text\"])\n",
    "sim = cosine_similarity(tfidf)\n",
    "\n",
    "pairs = np.argwhere(sim > 0.95)  # sube el umbral\n",
    "eliminar = set()\n",
    "for i, j in pairs:\n",
    "    if i != j and j not in eliminar:\n",
    "        eliminar.add(j)\n",
    "\n",
    "print(f\"üîç Casi-duplicados detectados: {len(eliminar)}\")\n",
    "\n",
    "df_clean = df.drop(list(eliminar)).reset_index(drop=True)\n",
    "print(f\"‚úÖ Dataset final sin duplicados: {len(df_clean)} filas\")\n",
    "\n",
    "# --- 4. Guardado ---\n",
    "out = Path(\"../data/processed/clean_v2/corpus_politico_codificado_utf8_clean_v2.csv\")\n",
    "out.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_clean[[\"text\",\"labels\"]].to_csv(out, index=False, encoding=\"utf-8\")\n",
    "print(\"üíæ Guardado en:\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c719f9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  labels\n",
      "0             Habla de verdad y solo cuenta su parte       0\n",
      "1  La fuerza del pueblo es m√°s fuerte que cualqui...       3\n",
      "2  M√°s del 60 % de los empleos creados en pandemi...       2\n",
      "3          No hay fuerza m√°s grande que la esperanza       3\n",
      "4  Se llena la boca de patria y vac√≠a los bolsill...       0\n",
      "5  M√°s de 50 000 escolares abandonaron clases tra...       2\n",
      "6      El sol volver√° a brillar sobre nuestra tierra       3\n",
      "7  Dice que ama al pa√≠s, pero lo ve como un negoc...       0\n",
      "8  Se dice ejemplo, pero su historia est√° llena d...       0\n",
      "9  El 45 % de los j√≥venes peruanos trabaja sin co...       2\n",
      "Distribuci√≥n: {0: 250, 2: 250, 3: 246, 1: 244}\n",
      "‚úÖ Dataset barajado guardado en: ..\\data\\processed\\clean_v2\\corpus_politico_codificado_utf8_clean_v2_shuffled.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Carga el dataset limpio\n",
    "df = pd.read_csv(\"../data/processed/clean_v2/corpus_politico_codificado_utf8_clean_v2.csv\")\n",
    "\n",
    "# Mezcla aleatoria reproducible\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Verifica orden\n",
    "print(df.head(10))\n",
    "print(\"Distribuci√≥n:\", df[\"labels\"].value_counts().to_dict())\n",
    "\n",
    "# Guarda barajado\n",
    "out_path = Path(\"../data/processed/clean_v2/corpus_politico_codificado_utf8_clean_v2_shuffled.csv\")\n",
    "df.to_csv(out_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"‚úÖ Dataset barajado guardado en: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cd87ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuci√≥n global: Counter({0: 250, 2: 250, 3: 246, 1: 244})\n",
      "Por fold (val):\n",
      "0 Counter({0: 60, 3: 52, 1: 46, 2: 40})\n",
      "1 Counter({3: 55, 0: 51, 2: 51, 1: 41})\n",
      "2 Counter({2: 52, 0: 52, 1: 51, 3: 43})\n",
      "3 Counter({1: 57, 2: 50, 3: 46, 0: 45})\n",
      "4 Counter({2: 57, 3: 50, 1: 49, 0: 42})\n",
      "‚úÖ Guardado maestro con folds: ..\\data\\processed\\clean_v2\\folds\\corpus_clean_v2_folds.csv\n",
      "üíæ fold 0: 792 train | 198 val  ->  train_fold0.csv / val_fold0.csv\n",
      "üíæ fold 1: 792 train | 198 val  ->  train_fold1.csv / val_fold1.csv\n",
      "üíæ fold 2: 792 train | 198 val  ->  train_fold2.csv / val_fold2.csv\n",
      "üíæ fold 3: 792 train | 198 val  ->  train_fold3.csv / val_fold3.csv\n",
      "üíæ fold 4: 792 train | 198 val  ->  train_fold4.csv / val_fold4.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, hashlib\n",
    "from collections import Counter\n",
    "\n",
    "# 1) cargar el barajado\n",
    "DATA = Path(\"../data/processed/clean_v2/corpus_politico_codificado_utf8_clean_v2_shuffled.csv\")\n",
    "df = pd.read_csv(DATA, encoding=\"utf-8\")\n",
    "assert {\"text\",\"labels\"}.issubset(df.columns), df.columns\n",
    "\n",
    "SEED = 42\n",
    "N_FOLDS = 5\n",
    "\n",
    "# 2) group_id para evitar fuga (coloca en mismo fold textos casi-iguales)\n",
    "def norm_for_group(s: str) -> str:\n",
    "    s = str(s).lower()\n",
    "    s = re.sub(r\"\\d+%\",\"<pct>\", s)\n",
    "    s = re.sub(r\"\\d+\",\"<num>\", s)\n",
    "    s = re.sub(r\"[^\\w\\s√°√©√≠√≥√∫√º√±]\",\" \", s)\n",
    "    s = re.sub(r\"\\s+\",\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "df[\"group_id\"] = df[\"text\"].apply(lambda t: hashlib.md5(norm_for_group(t).encode()).hexdigest())\n",
    "\n",
    "# 3) StratifiedGroupKFold si est√° disponible; si no, fallback a StratifiedKFold\n",
    "try:\n",
    "    from sklearn.model_selection import StratifiedGroupKFold\n",
    "    sgkf = StratifiedGroupKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "    splitter = sgkf.split(df, y=df[\"labels\"], groups=df[\"group_id\"])\n",
    "except Exception:\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    print(\"‚ö†Ô∏è scikit-learn sin StratifiedGroupKFold; usando StratifiedKFold (sin grupos).\")\n",
    "    sgkf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "    splitter = sgkf.split(df, y=df[\"labels\"])\n",
    "\n",
    "# 4) asignar fold a cada fila\n",
    "df[\"fold\"] = -1\n",
    "for fold_id, (train_idx, val_idx) in enumerate(splitter):\n",
    "    df.loc[val_idx, \"fold\"] = fold_id\n",
    "assert (df[\"fold\"]>=0).all(), \"Hay filas sin fold.\"\n",
    "\n",
    "# 5) reporte r√°pido\n",
    "print(\"Distribuci√≥n global:\", Counter(df[\"labels\"]))\n",
    "print(\"Por fold (val):\")\n",
    "for k in range(N_FOLDS):\n",
    "    print(k, Counter(df[df[\"fold\"]==k][\"labels\"]))\n",
    "\n",
    "# 6) exportar: (a) un solo CSV con fold, (b) pares train/val por fold\n",
    "OUT_DIR = Path(\"../data/processed/clean_v2/folds\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# (a) maestro con fold\n",
    "master_path = OUT_DIR / \"corpus_clean_v2_folds.csv\"\n",
    "df.to_csv(master_path, index=False, encoding=\"utf-8\")\n",
    "print(\"‚úÖ Guardado maestro con folds:\", master_path)\n",
    "\n",
    "# (b) archivos por fold\n",
    "for k in range(N_FOLDS):\n",
    "    train_df = df[df[\"fold\"]!=k][[\"text\",\"labels\"]].reset_index(drop=True)\n",
    "    val_df   = df[df[\"fold\"]==k][[\"text\",\"labels\"]].reset_index(drop=True)\n",
    "    train_path = OUT_DIR / f\"train_fold{k}.csv\"\n",
    "    val_path   = OUT_DIR / f\"val_fold{k}.csv\"\n",
    "    train_df.to_csv(train_path, index=False, encoding=\"utf-8\")\n",
    "    val_df.to_csv(val_path, index=False, encoding=\"utf-8\")\n",
    "    print(f\"üíæ fold {k}: {len(train_df)} train | {len(val_df)} val  ->  {train_path.name} / {val_path.name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beto_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
